{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4920\n",
      "Number of classes: 41\n",
      "Class distribution:\n",
      " Disease\n",
      "Fungal infection                           120\n",
      "Hepatitis C                                120\n",
      "Hepatitis E                                120\n",
      "Alcoholic hepatitis                        120\n",
      "Tuberculosis                               120\n",
      "Common Cold                                120\n",
      "Pneumonia                                  120\n",
      "Dimorphic hemorrhoids (piles)              120\n",
      "Heart attack                               120\n",
      "Varicose veins                             120\n",
      "Hypothyroidism                             120\n",
      "Hyperthyroidism                            120\n",
      "Hypoglycemia                               120\n",
      "Osteoarthristis                            120\n",
      "Arthritis                                  120\n",
      "(vertigo) Paroymsal  Positional Vertigo    120\n",
      "Acne                                       120\n",
      "Urinary tract infection                    120\n",
      "Psoriasis                                  120\n",
      "Hepatitis D                                120\n",
      "Hepatitis B                                120\n",
      "Allergy                                    120\n",
      "hepatitis A                                120\n",
      "GERD                                       120\n",
      "Chronic cholestasis                        120\n",
      "Drug Reaction                              120\n",
      "Peptic ulcer disease                       120\n",
      "AIDS                                       120\n",
      "Diabetes                                   120\n",
      "Gastroenteritis                            120\n",
      "Bronchial Asthma                           120\n",
      "Hypertension                               120\n",
      "Migraine                                   120\n",
      "Cervical spondylosis                       120\n",
      "Paralysis (brain hemorrhage)               120\n",
      "Jaundice                                   120\n",
      "Malaria                                    120\n",
      "Chicken pox                                120\n",
      "Dengue                                     120\n",
      "Typhoid                                    120\n",
      "Impetigo                                   120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "input_file = \"DiseaseAndSymptoms.csv\"\n",
    "data = pd.read_csv(input_file)\n",
    "data.columns = [col.replace(\"_\", \" \") for col in data.columns]\n",
    "data = data.apply(lambda x: x.str.replace(\"_\", \" \") if x.dtype == \"object\" else x)\n",
    "data[\"Disease\"] = data[\"Disease\"].replace(\"Peptic ulcer diseae\", \"Peptic ulcer disease\")\n",
    "data[\"Disease\"] = data[\"Disease\"].replace(\"Dimorphic hemmorhoids(piles)\", \"Dimorphic hemorrhoids (piles)\")\n",
    "\n",
    "# Clean and combine symptoms\n",
    "symptom_cols = [col for col in data.columns if \"Symptom\" in col]\n",
    "data[\"Symptoms\"] = data[symptom_cols].apply(\n",
    "    lambda row: \" \".join(sorted(set([s.strip() for s in row if pd.notna(s)]))), axis=1\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(f\"Number of rows: {len(data)}\")\n",
    "disease_list = sorted(data[\"Disease\"].unique())\n",
    "num_classes = len(disease_list)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Class distribution:\\n\", data[\"Disease\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3936, Validation samples: 984\n"
     ]
    }
   ],
   "source": [
    "# Split data (stratified)\n",
    "X_train, X_val, y_train_labels, y_val_labels = train_test_split(\n",
    "    data[\"Symptoms\"], data[\"Disease\"], test_size=0.2, random_state=42, stratify=data[\"Disease\"]\n",
    ")\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (3936, 41), Validation labels shape: (984, 41)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical([disease_list.index(d) for d in y_train_labels], num_classes=num_classes)\n",
    "y_val = tf.keras.utils.to_categorical([disease_list.index(d) for d in y_val_labels], num_classes=num_classes)\n",
    "print(f\"Training labels shape: {y_train.shape}, Validation labels shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (3936, 200)\n",
      "Validation embeddings shape: (984, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m51,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)             │         \u001b[38;5;34m5,289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,641</span> (350.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,641\u001b[0m (350.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,641</span> (350.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,641\u001b[0m (350.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load BioWordVec extrinsic embeddings\n",
    "word2vec_path = r\"C:\\Users\\ACER\\Downloads\\bio_embedding_extrinsic.bin\"  # Update with your path\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "\n",
    "# Function to get average embedding\n",
    "def get_symptom_embedding(text, wv):\n",
    "    words = text.split()\n",
    "    vectors = [wv[word] for word in words if word in wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(wv.vector_size)\n",
    "\n",
    "# Generate embeddings\n",
    "X_train_emb = np.array([get_symptom_embedding(text, word_vectors) for text in X_train])\n",
    "X_val_emb = np.array([get_symptom_embedding(text, word_vectors) for text in X_val])\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"Training embeddings shape: {X_train_emb.shape}\")  # (3936, 200)\n",
    "print(f\"Validation embeddings shape: {X_val_emb.shape}\")  # (984, 200)\n",
    "\n",
    "# Build classifier\n",
    "inputs = Input(shape=(word_vectors.vector_size,))  # 200D\n",
    "x = Dense(256, activation=\"relu\")(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1994 - loss: 3.2893\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91362, saving model to biowordvec_diagnosis_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2071 - loss: 3.2635 - val_accuracy: 0.9136 - val_loss: 0.9805\n",
      "Epoch 2/20\n",
      "\u001b[1m118/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - loss: 0.9192\n",
      "Epoch 2: val_accuracy improved from 0.91362 to 0.99695, saving model to biowordvec_diagnosis_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.9084 - val_accuracy: 0.9970 - val_loss: 0.1727\n",
      "Epoch 3/20\n",
      "\u001b[1m120/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.2952\n",
      "Epoch 3: val_accuracy improved from 0.99695 to 0.99898, saving model to biowordvec_diagnosis_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.2938 - val_accuracy: 0.9990 - val_loss: 0.0629\n",
      "Epoch 4/20\n",
      "\u001b[1m122/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.1468\n",
      "Epoch 4: val_accuracy improved from 0.99898 to 1.00000, saving model to biowordvec_diagnosis_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.1466 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
      "Epoch 5/20\n",
      "\u001b[1m 94/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0927\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0901 - val_accuracy: 1.0000 - val_loss: 0.0162\n",
      "Epoch 6/20\n",
      "\u001b[1m119/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0661\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0658 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 7/20\n",
      "\u001b[1m113/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0460\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0457 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 8/20\n",
      "\u001b[1m103/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0370\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0365 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 9/20\n",
      "\u001b[1m110/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0256\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 10/20\n",
      "\u001b[1m118/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0185\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0185 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 11/20\n",
      "\u001b[1m116/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0193\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "\u001b[1m104/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0142\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0143 - val_accuracy: 1.0000 - val_loss: 9.2346e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m111/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0130\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 9.3137e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m117/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0128\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0126 - val_accuracy: 1.0000 - val_loss: 4.6374e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m117/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0103\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 4.4987e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m118/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0081\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 5.2692e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m116/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0101\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0100 - val_accuracy: 1.0000 - val_loss: 3.5049e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m115/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0095\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 1.8234e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m113/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.8593e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m116/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0045\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 2.1525e-04\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\"biowordvec_diagnosis_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_emb, y_train,\n",
    "    validation_data=(X_val_emb, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved symptom embeddings to symptom_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "symptom_texts = data[\"Symptoms\"].tolist()\n",
    "embeddings = np.array([get_symptom_embedding(text, word_vectors) for text in symptom_texts])\n",
    "\n",
    "# Save embeddings to .npy file\n",
    "embedding_dict = {\"symptoms\": symptom_texts, \"embeddings\": embeddings}\n",
    "npy_path = \"symptom_embeddings.npy\"\n",
    "np.save(npy_path, embedding_dict)\n",
    "print(f\"Saved symptom embeddings to {npy_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
